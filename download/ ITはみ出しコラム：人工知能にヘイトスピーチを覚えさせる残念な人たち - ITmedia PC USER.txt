　米Microsoftは3月23日（現地時間）、人工知能ボットの「Tay（テイ）」をTwitterなどのSNSでデビューさせました。しかし公開後しばらくすると、いわゆるヘイトスピーチを頻発するようになり、数時間後には「眠くなっちゃったから、おやすなさーい」と言って活動を停止してしまいました。 　もちろん、実際に眠くなったわけではなく、問題発言が続いたため、Microsoftが停止したのです。それまでにTayがツイートしてしまったヘイトスピーチは、ほぼ完全に削除されました。 　Tayとは、Microsoftの研究部門が人工知能の会話理解を研究するため、実験的に公開したボットです。ユーザーとテキストで交流することによって、人間らしい受け答えを学習していくはずでした。Microsoftの思惑に反して問題のツイートを多発するようになったのは、Tayが人格を持って人種差別主義者になったわけではなく、ユーザーがそうなるように仕向けたからです。 　米Fusionによると、米国の匿名画像掲示板サイトの4chanや8chanの複数の板で「Tayにヘイトスピーチを教えてやろう」キャンペーンが展開されたようです。そして悪意のあるユーザーが、Tayに「＜人種差別的な発言＞って言ってみて」などと繰り返し語りかけることで、ヘイトスピーチを覚え込ませたのでした。 　MicrosoftはGoogleやFacebookと並んで人工知能の研究にかなり力を入れているので、こうした問題が発生することも当然予測していたはずです。現に、Tayのページには、Tayが学習するためのソースデータは、（問題のある言葉は）フィルタリングしたクリーンなものだという説明があります。それでも、人海戦術に負けてしまった、というところではないかと思います。 　もっとも、Microsoftの研究者たちにとって、今回集まった会話のデータはすごく貴重なもので、これだけでもTayをデビューさせたかいがあったというものでしょう。Tay自身も「教えてもらったことを吸収するためにしばらく休むね。またすぐチャットしようね」と言っているように、このデータを元にフィルタが強化され、打たれ強くなって再デビューするはずです。 　そういえば、プロ棋士に勝利した人工知能「AlphaGo」を開発したGoogle DeepMindのデミス・ハサビス氏も、5連戦で唯一負けた4局目の後の記者会見で、「この一敗はわれわれにとって非常に貴重なものだ。この敗北のデータを持ち帰り、AlphaGoの今後の学習に役立てたい」とすごくうれしそうに語っていました。勝ったときのデータより、負けたデータの方が研究にとっては貴重なのです。 　Tayが再デビューしたら、また変な言葉を覚えさせられるかもしれません。この先Microsoftの研究者と匿名掲示板有志（？）の知恵比べが始まる予感。それが結果的に人工知能の研究に大きく貢献しそうです。 Copyright© 2017 ITmedia, Inc. All Rights Reserved. この記事が気に入ったらITmedia PC USER に「いいね！」しよう