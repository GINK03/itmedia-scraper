　「人工知能（AI）研究の発展により、数十年ではなく数年後には、自律型兵器（autonomous weapon）の開発が可能になり、その代償は大きいだろう。自律型兵器は、火薬、核兵器に続く、戦争における第三の革命とみなされている」──。主に人工知能（AI）の安全性について研究する非営利の研究組織Future of Life Institute（FLI）は7月28日（現地時間）、アルゼンチンのブエノスアイレスで開催のIJCAI（人工知能国際会議）2015のオープニングで自律型兵器の開発禁止を呼び掛ける公開書簡を発表した。 　書簡の著者らは、人間の判断を介さない自律型兵器の使用は、戦闘開始の閾値を低くし、結果的に大規模な人命損失につながると主張する。また、AI兵器は核兵器と比較して開発が容易で低コストな上、監視が困難だ。さらに、コピーも比較的簡単なこともあり、ブラックマーケットに出回り、すぐに暗殺やテロに使われることになる恐れがあるという。「自律型兵器は未来のカラシニコフ銃になる」。 　FLIはSkypeの共同創業者ジャーン・タリン氏やと米マサチューセッツ工科大学のマックス・テグマーク教授らが立ち上げた研究組織。イーロン・マスク氏、スティーブン・ホーキンス博士、人工知能研究で知られるスチュワート・ラッセル教授らが顧問として名を連ねている。 　この書簡には、タリン氏、マスク氏、ホーキンス博士、ラッセル教授などのFLI創業者や顧問に加え、米Appleの共同創業者であるスティーブ・ウォズニアック氏、Google傘下のDeepMindのデミス・ハサビスCEO、ヒューマノイドロボット研究で知られる東京大学の中村佳彦教授、Microsoft Researchのエリック・ホロヴィッツ氏、Facebook人工知能ラボのヤン・ルカン教授、哲学者のノーム・チョムスキー氏など、1000人以上が署名している。 Copyright© 2017 ITmedia, Inc. All Rights Reserved.